---
title: "re1"
format: html
editor: visual
---

# Setup

```{r}
library(geosphere)
library(phenocamr)
library(here)
library(GenSA)
library(dplyr)
library(readr)
library(lubridate)
library(terra)

if (!dir.exists(here("data"))) {
  dir.create(here("data"))
}
```

```{r}
# Download the data
phenocamr::download_phenocam(
  site = "harvard$",      
  veg_type = "DB",        # Deciduous broadleaf vegetation
  roi_id = "1000",        # region ID
  daymet = TRUE,          # Daymet weather data 
  phenophase = TRUE,      # Phenophase dates
  trim = 2022,            
  out_dir = here("data")    
)
```

```{r}
# 1. Read the data. We use "#" to skip the metadata lines at the top of the file
harvard_phenocam_data <- read_csv(
  here("data", "harvard_DB_1000_3day.csv"),
  comment = "#"
)

# 2. Create 'harvard_temp' (calculate Tmean)
harvard_temp <- harvard_phenocam_data %>%
  mutate(date = as.Date(date)) %>%
  mutate(year = as.numeric(format(date, "%Y"))) %>%
  group_by(year) %>%
  mutate(
    tmean = (tmax..deg.c. + tmin..deg.c.) / 2
  ) %>%
  ungroup() %>%
  select(date, year, tmean)

# Check the result
head(harvard_temp)
```

```{r}
# 1. Read the data
harvard_phenocam_data_transition <- read_csv(
  here("data", "harvard_DB_1000_3day_transition_dates.csv"),
  comment = "#"
)

harvard_phenology <- harvard_phenocam_data_transition %>%
  # 2. Filter for the start of spring (rising greenness)
  filter(direction == "rising", gcc_value == "gcc_90") %>%
  
  # 3. Create the 'year' and 'doy' columns from the date
  mutate(
    trans_date = as.Date(transition_25),         # Convert text to date
    year = as.numeric(format(trans_date, "%Y")), # Extract year 
    doy = as.numeric(format(trans_date, "%j"))   # Extract day of year 
  ) %>%
  
  # 4. Select only what we need for the model
  select(year, doy)

# Check the result 
print(head(harvard_phenology))
```

# How to improve the model

The model used in chapter 6 is a simple Growing Degree Day (GDD) model. It assumes that temperature is the only driver of spring leaf-out. Once the daily temperature exceeds a base threshold (Tbase), the plant accumulates "heat units." When the bucket of heat units is full (F∗), leaves appear.

## Dormancy

Vegetation have a sleep mode called dormancy to protect themselves from winter. This prevent them to respond to warmth until they have experienced enough cold weather (chilling) to wake up. Including this dormancy parameter prevents the model from predicting leaf-out during warm days in early winter. The heat budget is locked until the cold budget is full.

In order to apply this to the model, we could add a a rule where GDD accumulation only starts after a certain number of cold days have passed.

## Soil temperature

The current model uses air temperature but vegetation have roots in the ground which is warming up slower that than air. Roots need to be active to pump water up to the buds before the leaves can expand. If the soil is still frozen, the roots can't function, even if the air is warm.

The model could be improved by also estimating soil temperature considering that it is often a lagged and damped version of air temperature.

## Photoperiod

Temperatures varies greatly year to year but the length of the day is perfectly consistent and vegetation usually use day length like a calendar. It helps the plant distinguish between a warm day in February (short days) and a warm day in May (long days) for example.

We can implement this by modifying the critical threshold (F\*). Plants need less heat to leaf out if the days are very long (late spring), but more heat if the days are short (early spring).

# The basic GGD model

```{r}
gdd_model <- function(par, temp) {
  
  # 1. We unpack the parameters (for readability)
  t_base <- par[1]  # The base temperature (like 5°C)
  f_crit <- par[2]  # The critical heat threshold (like 300 GDD)
  
  # 2. We calculate daily heat units (forcing). If temp > t_base, we accumulate heat. If colder, we accumulate 0.
  # We use pmax() which is a faster version of ifelse() for vectors.
  daily_forcing <- pmax(0, temp - t_base)
  
  # 3. We calculate the state of forcing (cumulative sum). This creates a running total of heat for every day of the year.
  accumulated_forcing <- cumsum(daily_forcing)
  
  # 4. We find the trigger day. Leaf-out happens when accumulated heat >= treshold 
  # We take the first one ([1]) using which().
  doy <- which(accumulated_forcing >= f_crit)[1]
  
  return(doy)
}
```

# Adding photoperiod

Now we want to improve the model by adding the photoperiod. The concept is that if the days are long (late spring), trees lower their defense mechanisms and need less heat to leaf out.

To implement this, we need two things:

-   Data: We need to know the day length (in hours) for every day of the year.

-   Math: We need a formula where longer days make the threshold (Fcrit) smaller.

## Calculating the day length

The length of the day depends on latitude and the day of the year. We can use the geosphere package for this.

```{r}
# As an example, we calculate day length for Harvard Forest for all 365 days
doy_vector <- 1:365
day_length <- daylength(lat = 90, doy = doy_vector)

# Let's visualize it to make sure it makes sense (Should peak in June)
plot(day_length, type='l', ylab="Hours of Daylight", xlab="Day of Year")
```

## Photoperiod GDD model

```{r}
# The Photoperiod GDD Model
model_photoperiod <- function(par, temp, latitude = 42.5) {
  
  # 1. Unpack Parameters. Now we have 3 parameters to optimize
  t_base <- par[1]      # Base temperature
  f_crit <- par[2]      # Heat treshold 
  k_photo <- par[3]     # Photoperiod sensitivity
  
  # 2. We calculate daily heat units
  daily_forcing <- pmax(0, temp - t_base)
  
  # 3. We calculate accumulated heat 
  accumulated_forcing <- cumsum(daily_forcing)
  
  # 4. We calculate the day length for every day of the year (length of temp vector)
  doy_vector <- 1:length(temp) 
  day_len <- geosphere::daylength(lat = latitude, doy = doy_vector)
  
  # 5. We define the Variable threshold. The threshold changes every day. Longer days = lower threshold.
  daily_threshold <- f_crit - (k_photo * day_len)
  
  # 6. We finally find the trigger day.
  doy <- which(accumulated_forcing >= daily_threshold)[1]
  
  return(doy)
}
```

## The cost function

```{r}
# Define the Cost Function
rmse_photoperiod <- function(par, data) {
  
  # 1. drivers = temp, validation = observed dates
  drivers <- data$drivers
  validation <- data$validation
  
  # 2. We Run the model for every year in the driver data. This creates a dataframe of "year" and "pred" (predicted doy)
  predictions <- drivers %>%
    group_by(year) %>%
    summarise(
      pred = model_photoperiod(
        par = par, 
        temp = tmean  
      )
    )
  
  # 3. We compare to reality by joining predictions with the 'validation' data (observed 'doy')
  comparison <- left_join(predictions, validation, by = "year")
  
  # 4. Walculate RMSE 
  rmse <- sqrt(mean((comparison$pred - comparison$doy)^2, na.rm = TRUE))
  
  return(rmse)
}
```

## Optimization of the RMSE

```{r}
# 1. Package the data for the function
data_for_optim <- list(
  drivers = harvard_temp,
  validation = harvard_phenology
)

# 2. We define the lower and upper boundaries of the 3 parameters
#                 T_base,  F_crit,  k_photo
lower_bounds <- c(   -5,      50,       0)
upper_bounds <- c(   10,     500,      20)

# 3. First guess
start_par <- c(0, 200, 5) 

# 4. We run the optimization
optim_result <- GenSA(
  par = start_par,
  fn = rmse_photoperiod,    # Our cost function
  lower = lower_bounds,
  upper = upper_bounds,
  control = list(max.call = 4000), # Limit it to 4000 tries
  data = data_for_optim     
)

# 5. Extract the best parameters
best_pars <- optim_result$par

print("Optimal parameters:")
print(paste("T_base:", round(best_pars[1], 2)))
print(paste("F_crit:", round(best_pars[2], 2)))
print(paste("k_photo:", round(best_pars[3], 2)))
print(paste("Final RMSE:", round(optim_result$value, 3)))
```

# Spatial scaling

Now that we have the optimal parameters we need to apply this model to a map of temperature to observe the predicted leaf-out dates across the New England region. In order to do this we need to download the gridded daily temperature for the region and then run the `model_photoperiod` function on every pixel of that map.

```{r}
# 1. Download the temperature raster data
dest_file <- here("data", "daymet_2012_subset.nc")

if (!file.exists(dest_file)) {
  download.file(
    url = "https://github.com/fabern/handfull_of_pixels/raw/refs/heads/main/data/DAYMET.004_2012/DAYMET.004_1km_aid0001.nc",
    destfile = dest_file,
    mode = "wb"
  )
}

# 2. Load and prepare the data
r_daymet <- terra::rast(dest_file)

# We calculate the Tmean for the map
tmean_map <- (r_daymet["tmax"] + r_daymet["tmin"]) / 2

# We limit to the first 180 days to save processing time because spring phenology happens in the first half of the year
tmean_map <- subset(tmean_map, 1:180)

# 4. Apply the model
# We use the parameters found in the optimization
my_best_par <- c(3.23, 333.25, 8.3) 

# We apply the 'model_photoperiod' function to every pixel
predicted_map <- terra::app(
  x = tmean_map,           # The temperature layers
  fun = model_photoperiod, # The custom function
  par = my_best_par,       # The optimized parameters
  latitude = 43.0          # The latitude for the Boston region
)

minmax(predicted_map) # We check the minimum and the maximum values
```

```{r}
# 5. Result visualization 
plot(predicted_map, 
     main = "Predicted leaf-out date (Day of Year)", 
     #col = map.pal("viridis", 100),
     range = c(100, 150)) 
```

